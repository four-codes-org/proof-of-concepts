import json
import re
import pathlib
import boto3
import urllib
import logging

class s3Process():
    tempdir = "/tmp/"
    ChecksumAlgorithm = 'SHA256'

    def __init__(self, bucket, key):
        self.bucket = bucket
        self.key = key
        self.s3 = boto3.resource('s3')
        self.s3Client = boto3.client('s3')
        self.parentPath = pathlib.PurePath(self.key).parent
        self.childName = pathlib.PurePath(self.key).name

    def download(self):
        downloadLocation = self.tempdir + self.childName
        self.s3.meta.client.download_file(self.bucket, self.key, downloadLocation)
        return downloadLocation

    def delete(self, destinationBucket=None):
        targetBucket = destinationBucket if destinationBucket != None else self.bucket
        return self.s3Client.delete_object(Bucket=targetBucket, Key=self.key)

    def upload(self, uploadKey):
        return self.s3.meta.client.upload_file(uploadKey, self.bucket, uploadKey)

    def copy(self, destinationBucket, customLocation=None):
        targetPath = customLocation + self.childName if customLocation != None else self.key
        source = {'Bucket': self.bucket, 'Key': self.key}
        return self.s3Client.copy_object(CopySource=source, Bucket=destinationBucket, Key=targetPath, TaggingDirective='COPY', ChecksumAlgorithm=self.ChecksumAlgorithm)

    def createNewTag(self, t_name, t_value):
        tagging = {'TagSet': [{'Key': t_name, 'Value': t_value}]}
        return self.s3Client.put_object_tagging(Bucket=self.bucket, Key=self.key, Tagging=tagging)

    def objectState(self):
        return 'Contents' in self.s3Client.list_objects(Bucket=self.bucket, Prefix=self.key)

    def getTags(self):
        tag = self.s3Client.get_object_tagging(Bucket=self.bucket, Key=self.key)
        return tag['TagSet']

    def getSpecificTagDetails(self, t_name):
        tags = self.s3Client.get_object_tagging(Bucket=self.bucket, Key=self.key)
        data = tags['TagSet']
        print(data)
        if data == []:
            return False
        else:
            for element in data:
                if element['Key'] == t_name:
                    return element['Value']
            return False

    def updateTags(self, destinationBucket=None,updationTags=None):
        targetBucket = destinationBucket if destinationBucket != None else self.bucket
        updationTagLists = updationTags if updationTags != None else self.getTags()
        return self.s3Client.put_object_tagging(Bucket=targetBucket, Key=self.key, Tagging={'TagSet': updationTagLists})

    def logPoster(self, event, state):
        return json.dumps({'event': event, 'Bucket': self.bucket, 'fileName': self.key, 'processState': state})

    def ignorePathPosition(self, pathPosition):
        data = re.split(r'/', self.key)
        return ("/".join(data[pathPosition:]))

def lambda_handler(event, context):
    print(event)
    """ Event Capture process"""
    eventName = event['detail']['eventName']
    eventBucket = urllib.parse.unquote_plus(event['detail']['requestParameters']['bucketName'])
    key = urllib.parse.unquote_plus(event['detail']['requestParameters']['key'])

    """ Logger initiate process"""
    
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    """ Class initiate process"""
    _s3 = s3Process(eventBucket, key)

    """ If an object exists in the event bucket, it will execute based on conditions."""
    if (_s3.objectState()):

        """ C_BA process validated"""
        if (eventName == "PutObject" or eventName == "CompleteMultipartUpload") and (eventBucket == "sst-s3-bca-cnxcp-sitizit-safe"):
            if "C_D" in key:
                uploadSftpIntranetBucket = "sst-s3-bca-cnxcp-sitizgut-sftp"
                _s3.copy(uploadSftpIntranetBucket)
                _s3.createNewTag("zone", "intranet")

            elif "C_B" in key:
                safeBucket = "sst-s3-bca-cnxcp-sitezit-safe"
                _s3.createNewTag("zone", "intranet")
                _s3.copy(safeBucket)
                _s3.delete()
            else: # C_BA
                safeBucket = "sst-s3-bca-cnxcp-sitezit-safe"
                uploadBucket = "cp-s3-sit.nttdata.com.sg"
                _s3.createNewTag("zone", "intranet")
                _s3.copy(safeBucket)
                print(uploadBucket)
                _s3.copy(uploadBucket)

            """ t2 process validated"""
        elif (eventName == "PutObject" or eventName == "CompleteMultipartUpload") and (eventBucket == "cp-s3-sit.intranet.nttdata.com.sg"):
            scanBucket = "sst-s3-bca-cnxcp-sitmzna-scanning"
            safeBucket = "sst-s3-bca-cnxcp-sitizit-safe"
            _s3.createNewTag("zone", "intranet")
            _s3.copy(scanBucket)
            _s3.copy(safeBucket)
            _s3.delete()
            
        elif (eventName == "PutObject" or eventName == "CompleteMultipartUpload") and (eventBucket == "sst-s3-bca-cnxcp-sit-fhq-dropinternal"):
            scanBucket = "sst-s3-bca-cnxcp-sitmzna-scanning"
            safeBucket = "sst-s3-bca-cnxcp-sitizit-safe"
            _s3.createNewTag("zone", "intranet")
            _s3.copy(scanBucket)
            _s3.copy(safeBucket)
            _s3.delete()

            """ SFTP(D_B & D_C) process validated"""
        elif (eventName == "PutObject" or eventName == "CompleteMultipartUpload") and (eventBucket == "sst-s3-bca-cnxcp-sitizgut-sftp"):
            if "D_B" in key:
                scanBucket = "sst-s3-bca-cnxcp-sitmzna-scanning"
                safeBucket = "sst-s3-bca-cnxcp-sitezit-safe"
                _s3.createNewTag("zone", "internet")
                _s3.copy(scanBucket)
                _s3.copy(safeBucket)
                _s3.delete()
            else:
                scanBucket = "sst-s3-bca-cnxcp-sitmzna-scanning"
                safeBucket = "sst-s3-bca-cnxcp-sitizit-safe"
                _s3.createNewTag("zone", "intranet")
                _s3.copy(scanBucket)
                _s3.copy(safeBucket)
                _s3.delete()

        else:
            logger.error(_s3.logPoster(eventName, "condition mismatch for processing"))
    else:
        logger.error(_s3.logPoster(eventName, "unknown events"))